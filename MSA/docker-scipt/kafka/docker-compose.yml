version: "3"

networks:
  kafka_network:

volumes:
  kafka01:
    driver: local
  kafka02:
    driver: local
  kafka03:
    driver: local

services:
  zookeeper01:
    image: confluentinc/cp-zookeeper:7.8.0
    hostname: zookeeper01
    container_name: zookeeper01
    ports:
      - "2181:2181"
    restart: unless-stopped
    environment:
      # zookeeper을 식별할 아이디
      # 단일 zookeeper을 사용할 것이기 때문에 의미있지는 않음
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      # 2888은 zokeeper을 여러개(주키퍼 앙상블)일 때, 서로 통신을 하기 위한 설정
      # 이 역시 단일 zookpper이기 때문에 의미 없음
      # 3888은 마스터를 위한 포트
      # ZOOKEEPER_SERVERS: zookeeper01:2888:3888
      # zookeeper가 클러스터를 구성할 때의 동기화 틱 시간 설정
      ZOOKEEPER_TICK_TIME: 2000
      # 초기화 제한 시간
      # 주키퍼 앙상블은 쿼럼을 통해 마스터를 설정함
      # 이때, 나머지 주키퍼들이 마스터에 연결되는 최대 시간 설정
      # 타임 아웃 시간은 ZOOKEEPER_TRICK_TIME*ZOOKEEPER_INIT_LIMIT = 2000*5 = 10,000(10초)가 됨
      # 단일 zookeeper을 사용할 것이기 때문에 의미있지는 않음
      ZOOKEEPER_INIT_LIMIT: 5
      # 마스터와 나머지들의 싱크 제한 시간
      # 시간 내에 싱크 응답이 오는 경우 클러스터가 정상적으로 구성되었다는 것을 알 수 있음
      # 싱크 시간은 ZOOKEEPER_TRICK_TIME*ZOOKEEPER_SYNC_LIMIT = 2000*2 = 4000(4초)가 됨
      ZOOKEEPER_SYNC_LIMIT: 2
    networks:
      - kafka_network 

  kafka01:
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka01
    container_name: kafka01
    ports:
      - "9092:9092"
      - "29092:29092"
    restart: unless-stopped
    environment:
      # kafka 브로커 아이디. unique한 값이여야 함
      KAFKA_BROKER_ID: 1    
      # 외부에서 접속하기 위한 리스너 설정
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka01:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      # KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka01:19092,EXTERNAL://127.0.0.1:9092,DOCKER://host.docker.internal:29092
      # 보안을 위한 프로토콜 매핑. 이 값은 KAFKA_ADVERTISED_LISTENERS와 함께 key-value로 지정함
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      # docker 내부에서 사용할 리스너 이름
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      # kafka가 연결될 zookeeper 지정.
      KAFKA_ZOOKEEPER_CONNECT: zookeeper01:2181
      # 로그 설정
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      # 요청 권한 부여. ACL(Access Control List) 접근 제어 목록
      # KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      # kafka 브로커가 접근 권한이 없어도 동작할 수 있도록 함
      # KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    networks:
      - kafka_network    
    volumes:
      - kafka01:/confluentinc/kafka
    depends_on:
      - zookeeper01

  kafka02:
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka02
    container_name: kafka02
    ports:
      - "9093:9093"
      - "29093:29093"
    restart: unless-stopped
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka02:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper01:2181
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      # KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      # KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    networks:
      - kafka_network
    volumes:
      - kafka02:/confluentinc/kafka    
    depends_on:
      - zookeeper01

  kafka03:
    image: confluentinc/cp-kafka:7.8.0
    hostname: kafka03
    container_name: kafka03
    ports:
      - "9094:9094"
      - "29094:29094"
    restart: unless-stopped
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka03:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: zookeeper01:2181
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      # KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
      # KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
    networks:
      - kafka_network    
    volumes:
      - kafka03:/confluentinc/kafka    
    depends_on:
      - zookeeper01
  
  kafka-connect-jdbc:
    build:
      context: ./
      dockerfile: Dockerfile-kafka-connect
    hostname: kafka-connect-jdbc
    container_name: kafka-connect-jdbc
    ports: 
      - "8083:8083"
    restart: unless-stopped
    networks:
      - kafka_network
    # volumes:
    #   # - /Users/chany/Study/kafka-jar/7.8.0:/etc/kafka-connect/jars
    #   - /Users/chany/Study/kafka-jar/7.8.0:/etc/kafka-connect/jars
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka01:19092,kafka02:19093,kafka03:19094
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: "connect"
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-config"
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "localhost"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_PLUGIN_PATH: "/usr/share/java, /etc/kafka-connect/jars"
    depends_on:
      - zookeeper01
      - kafka01
      - kafka02
      - kafka03
  # kafka-connect-jdbc:
  #   image: confluentinc/cp-kafka-connect-base:7.8.0
  #   hostname: kafka-connect-jdbc
  #   container_name: kafka-connect-jdbc
  #   ports: 
  #     - "8083:8083"
  #   restart: unless-stopped
  #   networks:
  #     - kafka_network 
  #   volumes:
  #     - /Users/chany/Study/kafka-jar/7.8.0:/etc/kafka-connect/jars
  #   environment:
  #     CONNECT_BOOTSTRAP_SERVERS: kafka01:19092,kafka02:19093,kafka03:19094
  #     CONNECT_REST_PORT: 8083
  #     CONNECT_GROUP_ID: "connect"
  #     CONNECT_CONFIG_STORAGE_TOPIC: "connect-config"
  #     CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
  #     CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
  #     CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
  #     CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  #     CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  #     CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  #     CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
  #     CONNECT_REST_ADVERTISED_HOST_NAME: "localhost"
  #     CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
  #     CONNECT_PLUGIN_PATH: "/usr/share/java, /etc/kafka-connect/jars"
  #   # command: ['confluent-hub install --no-prompt --component-dir /etc/kafka-connect/jars confluentinc/kafka-connect-jdbc:10.7.4',
  #   #         'curl -L -o /usr/share/java/confluentinc-kafka-connect-jdbc/lib/mysql-connector-java-8.0.23.jar https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.23/mysql-connector-java-8.0.23.jar']
  #   depends_on:
  #     - zookeeper01
  #     - kafka01
  #     - kafka02
  #     - kafka03

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    restart: always
    container_name: kafka-ui
    ports:
      - '8085:8080'
    environment:
      - KAFKA_CLUSTERS_0_NAME=local-kafka
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka01:19092,kafka02:19092,kafka03:19092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper01:2181
    depends_on:
      - kafka01
      - kafka02
      - kafka03
    networks:
      - kafka_network